\documentclass[sigconf, anonymous, review]{acmart}
\citestyle{acmnumeric}
\usepackage[utf8]{inputenc}
\usepackage{fancyvrb}

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  % TOGGLE ME to turn off all the commentary:
  \InputIfFileExists{no-editing-marks}{
    \def\noeditingmarks{}
  }

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      % Adapting to acmart's small margins
      \setlength{\marginparsep}{0.3em}
      \setlength{\marginparwidth}{1.4cm}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=orange,backgroundcolor=orange!25,bordercolor=orange,#1]{#2}}
      \newcommandx{\unsureF}[2][1=]{\todo[linecolor=orange,backgroundcolor=lightgray!25,bordercolor=orange,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
    \else
      \renewcommand{\todo}{}
      \newcommandx{\unsure}[2][1=]{{}}
      \newcommandx{\unsureF}[2][1=]{{}}
      \newcommandx{\info}[2][1=]{{}}
      \newcommandx{\change}[2][1=]{{}}
      \newcommandx{\inconsistent}[2][1=]{{}}
      \newcommandx{\critical}[2]{{}}
      \newcommand{\improvement}[1]{{}}
      \newcommandx{\resolved}[2][1=]{{}}

  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

\title{Interface design with SMT solvers: A study}

\author{undisclosed author/s}
\author{Facundo Domínguez}
\affiliation{
     \institution{Tweag}
     \country{Uruguay}
}
\email{facundo.dominguez@tweag.io}
\author{Arnaud Spiwack}
\affiliation{
     \institution{Tweag}
     \country{France}
}
\email{arnaud.spiwack@tweag.io}
\keywords{refinement types, Liquid Haskell, SMT solvers, library design}
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10010124.10010138.10010142</concept_id>
       <concept_desc>Theory of computation~Program verification</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10010124.10010138.10010140</concept_id>
       <concept_desc>Theory of computation~Program specifications</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program verification}
\ccsdesc[500]{Theory of computation~Program specifications}

\newcommand{\tc}[1]{{\small\texttt{#1}}}
\newcommand{\codeblocksize}{\fontsize{6.5}{9}\selectfont}
\newcommand{\sourcefile}[1]{\anon[#1 (in the attached artifact)]{{\scriptsize\url{https://github.com/facundominguez/liquidhaskell/blob/fd/rapier/tests/rapier/#1}}}}
\RecustomVerbatimEnvironment{verbatim}{Verbatim}{
    fontsize=\codeblocksize,
}
\newtheorem{principle}{Principle}

\begin{document}
\begin{abstract}
    This paper explores the use of Satisfiability Modulo Theories (SMT) solvers,
    specifically through Liquid Haskell, to enhance static checks of
    programming language interfaces. Traditional approaches in strongly typed
    languages balance type richness with interface usability. We present a
    third alternative: leveraging SMT solvers via refinement types to offload
    static checks from the type checker. Our study includes a comparative
    analysis of capture-avoiding substitution, demonstrating the advantages of
    Liquid Haskell over type-checker-based methods. Furthermore, we investigate
    the application of SMT solvers to unification, a more complex scenario,
    highlighting both the capabilities and current limitations of this
    approach. We showcase modifications to Liquid Haskell to support these
    advanced checks, demonstrating technical feasibility. The paper also
    argues for the broad applicability of SMT solvers in ensuring various
    program properties, suggesting that their integration can significantly
    improve both the power and convenience of static checks in programming.
\end{abstract}
\maketitle

\section{Introduction}

\change{Notes so that I[Arnaud] don't forget, principles: refinement types
  provide subtyping; refinement types have smaller minimal trusted code base,
  but you can choose how large the trusted code base is with assumptions; choose
  between abstract types and refinement types depending on the kind of property
  and go for what's easier} SMT solvers are useful to the ordinary activity of
programming. This is what we would like to convince the reader of. More
precisely, our claim is that an SMT solver well-integrated in the static checks
of a compiler, complements an ordinary type checker when composing programs.

The experience of programming with types is that of collaborating with the
compiler to write the programs with want to write. SMT solvers can be use much
the same.

SMT solvers, when it comes to their application to programming, are usually
paired with terms like ``formal methods'' or ``verification'' in the
literature~\cite{barnett05,demoura08,zinzin17,swamy22}. We would like to
challenge the wisdom that we reach for SMT-solver-based tools when we need
formal methods. We would benefit from using SMT solvers in mundane programs.

We will be arguing, in particular, that refinement type, in the guise of Liquid
Haskell~\cite{vazou14b}, is a tool that lets you do just that. Even tough Liquid
Hakell is also usually invoked together with phrases like ``formal methods'' or
``verification''~\cite{vazou14,lehmann21,liu20,redmond23}. We would like to
challenge the wisdom that Liquid Haskell is only for formal method as well.

Through a case study, will we argue, even though the technology isn't really
ready yet, for a future where programming, ordinary programming, is made easier
and more pleasant thanks to refinements types and SMT solvers. Our case study,
will be the handling of binders' scopes in compilers. A secondary contribution
is a prototype implementation of a theory of finite maps for Liquid Haskell's
solver, to support our case study, and which we discuss in
Section~\ref{extending-liquid-haskell}.

\section{Capture-avoiding substitutions}
\label{capture-avoiding-substitution}

Binding scope management is recognized as a persistent annoyance when writing compilers.
It's easy to get wrong and is a source of mistake to the point that many have
proposed disciplines to prevent mismanagement of scopes, like name capture.
The poster child is substitution like in
$(\lambda x. y)[y:=t]$. The result of this substitution is $\lambda x. t$.
Thus $(\lambda x. y)[y:=x]$ is $\lambda x. x$. An easy mistake!

Compiler authors have proposed many discipline to help make scope more
manageable.
The GHC Haskell compiler, for instance, uses an approach to avoid name capture called
\textit{the rapier}~\cite{peytonjones02secrets}. All term-manipulating functions
carry an additional \textit{scope} set containing all the
variables that appear free in its arguments. This set is
used both to decide what to rename a binder to, in order to avoid name capture,
and it is also used to skip renaming a binder if it wouldn't capture any free
variables. Figure~\ref{rapier-style-substitution} shows an implementation of
substitution
for the untyped lambda calculus.

\begin{figure}
\begin{verbatim}
data Exp = Var Int | App Exp Exp | Lam Int Exp

substitute :: Set Int -> Subst Exp -> Exp -> Exp
substitute scope s e0 = case e0 of
  Var i -> case lookupSubst i s of Nothing -> e0; Just e -> e
  App e0 e1 -> App (substitute scope s e0) (substitute scope s e1)
  Lam i e
    | member i scope,
      let j = freshVar scope ->
        Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
    | otherwise ->
        Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e

freshVar :: Set Int -> Int
freshVar s = case lookupMax s of Nothing -> 0; Just i -> i + 1
\end{verbatim}
\caption{Rapier style substitution}
\Description{Haskell implementation of substitution for untyped lambda terms using the rapier}
\label{rapier-style-substitution}
\end{figure}

\subsection{The foil}
\label{the-rapier-with-stronger-types}

The rapier wasn't enough, however, for \citet{maclaurin23} who report that
despite using the rapier they struggled with frequent scope issues in their
compiler. They set out to, enforce the scope properties of the rapier with
Haskell's type system. A stunt that has often been attempted, but
\cite{maclaurin23}'s approach, that they name \emph{the foil}, is probably the
first to succeed at enforcing such invariants without incurring an unreasonable
amount of boilerplate.

Here is our distillation of the properties that \citeauthor{maclaurin23} set
out to guarantee (see also \cite[Section~4]{maclaurin23}):
\begin{enumerate}
\item Every traversed binder must be added to the scope set, lest their name
      is later used instead of a fresh name.
\item \label{req:always-rename} Every traversed binder must be renamed if it's already a member of the
      scope set, because this name could otherwise be captured as above.
\item When renaming a binder, the new name must not belong to the scope set.
\item When renaming a binder, the occurrences of the old bound variable need
      to be substituted with the new name.
\item The initial scope set must contain the free variable of all the relevant
      arguments.
% \item The binders need to be removed from the domain of the substitution when
%       they are not in the scope set, otherwise the substitution will happily
%       replace occurrences of those bound variables! An alternative we use in
%       Figure~\ref{rapier-style-substitution} is to redefine the substitution to
%       map the variable of the binder to itself.
\end{enumerate}

\Citeauthor{maclaurin23} propose a library with types \tc{Scope n}, \tc{Name n}, and
\tc{Name\-Binder n l}. A value of type \tc{Scope n} is a set of names, where
the type index \tc{n} is the name of the set at the type level. A value of type \tc{Name n} is a name that
belongs to the set with type \tc{Scope n}. A value of type \tc{NameBinder n l} is
a name in the set with type \tc{Scope l} which results from adding such single
name to the set with type \tc{Scope n}. These types are to be used in
the abstract syntax tree of terms:

\begin{quotation}
\begin{verbatim}
data Exp n = Var (Name n)
           | App (Exp n) (Exp n)
           | forall l. Lam (NameBinder n l) (Exp l)
\end{verbatim}
\end{quotation}

Then the operations and type checking on the new types will guide the user into
respecting much of the scope requirements when implementing substitution.

\begin{verbatim}
substitute :: Distinct o => Scope o -> Subst Expr i o -> Expr i -> Expr o
\end{verbatim}

This type signature says that no names shadow each other in the scope set \tc{o}.
It also says that the substitution will take a expression with free variables in
a scope set \tc{i} and produce an expression with free variables in a scope set
\tc{o}.

There
are mechanisms to check that a scope set is a subset of another, to assert that no
name shadows another one in a given scope set, to reason that expressions
with free variables in one scope (\tc{Exp n}) can be coerced to expressions with
free variables in a superset (\tc{Exp l}), and to introduce scope sets that extend
others with freshly created names. They also provide an implementation of maps of
variables to expressions, that is the substitutions to apply, with an interface
that uses the new types as well. There is for instance the following function to
produce fresh variables:\unsure{can we name some of these mechanisms, for
  reference? \emph{e.g.} “that no name shadows one another (Distinct)”}

\begin{verbatim}
withRefreshed
  :: Distinct o
  => Scope o
  -> Name i
  -> (forall (o' :: S). DExt o o' => NameBinder o o' -> r)
  -> r
\end{verbatim}

Using the constraint \tc{DExt}, this type signature says that scope set \tc{o'}
extends the scope set \tc{o} with the given \tc{NameBinder o o'}. This binder
may have the same name as the provided \tc{Name i} if it was not present in
\tc{o}, otherwise it will be a fresh name. As another example, the following
function always produces a fresh name.

\begin{verbatim}
withFresh
  :: Distinct n
  => Scope n
  -> (forall l . DExt n l => NameBinder n l -> r )
  -> r
\end{verbatim}

With ingenious engineering and design, the foil meets its rather ambitious goal.
But it is unfortunate that the authors needed to be ingenious. All things equal,
we prefer program components to be straightforward. Because ingenious solutions
take time, and because straightforward solutions are easier to adapt when the
parameters of the problem evolve.
We would like to argue next that refinement types, like in Liquid Haskell, can
serve to reduce ingenuity in program design.


\subsection{A Liquid Haskell primer}

Liquid Haskell is a
plugin for Haskell. When given a program, Liquid Haskell
checks statically that the functions in the program respect signatures
provided by the programmer. There are two key differences between Liquid Haskell
signature checking and a classical type checker:

\begin{itemize}
  \item The checking process consists in generating logical assumptions which
        are then fed to an SMT solver, leveraging the powerful
        capabilities of SMT solvers to reason about numbers, arrays, strings, etc…
  \item Signatures are expressed with \emph{refinement types} of the form
        \tc{\{x:b | p\}}, which denotes values of type
        base type \tc{b} that satisfy predicate \tc{p}.
        Refinements are subject to subtyping in the same way as subsets in set
        theory, so that we have
\begin{verbatim}
{-@ f :: {x:Int | x > 1} -> {x:Int | x > 0} @-}
f :: Int -> Int
f x = x
\end{verbatim}
\end{itemize}

Liquid Haskell reads refinement type signatures and other annotations from
inside such special Haskell comments
\tc{\{-@ \ldots\ @-\}}. We will skip them in our snippets when it is unambiguous.

Liquid Haskell lets us express refinement types which relate arguments with each
other, and with the result. This will let us relate the variables and scope sets
of the rapier. For example, the \tc{freshVar} function can be given this signature

\begin{verbatim}
import Data.Set
{-@ assume freshVar :: s:Set Int -> {v:Int | not (member v s)} @-}
\end{verbatim}
\improvement{This doesn't have to be an assumption. It could also be proved,
  presumably. Based on the signatures for lookupMax and such. Maybe there's an
  interesting element to discuss about this: when ensuring invariants with sealed
  types, the correctness of every single function is assumed. With liquid type
  you have a choice: you can either assume it, or check it. Both choices are
  reasonable and depend on the circumstance.}

The predicates in the refinement types are in a language of expressions
referred to as the logic language. For the sake of this paper, we can
regard it as a subset of Haskell. Predicates are assembled both from
regular Haskell functions and functions that are
only available in the logic language.
A function like \tc{member}, which comes from the module \tc{Data.Set}
in the \tc{containers} package, is linked by Liquid Haskell to the
SMT solver's theory of sets.

Refinement type signatures starting with the \tc{assume} keyword declare that the
corresponding Haskell function should honor the signature, but it isn't
checked. When \tc{freshVar} is called in other functions, Liquid Haskell
will assume that the returned variable is fresh whatever the implementation
of \tc{freshVar} does. Removing the \tc{assume} keyword, on the other hand,
will have Liquid Haskell produce an error if it cannot check that
\tc{freshVar} behaves as advertised.


\subsection{The rapier, refined}
\label{the-rapier-with-refinement-types}

In this section we show how Liquid Haskell allows to introduce the needed
static checks for the rapier. And we hope, in a way that does not require
subtle or deep considerations. The code presented in this section is available in the file
\tc{Subst1.hs}.\footnote{The simplest approach with Liquid Haskell:
  \sourcefile{Subst1.hs}}

In order to deal with scope checks, we first define a type alias \tc{ScopeExp S},
that is the type of all
expressions whose free variables are in the set \tc{S}\footnote{In type aliases,
Liquid Haskell expects parameter names to start with an uppercase letter.}.

\begin{verbatim}
{-@ type ScopedExp S = {e:Exp | isSubsetOf (freeVars e) S} @-}
\end{verbatim}

Functions like \tc{isSubsetOf} and \tc{difference} come from the \tc{Data.\allowbreak Set}
module. The function \tc{freeVars} is in the same module as \tc{subs\-ti\-tute},
and collects the free variables of an expression. We note that this function
is only used in refinement type signatures, and in particular, it is not evaluated
when calling to \tc{substitute}.

\begin{verbatim}
freeVars :: Exp -> Set Int
freeVars e = case e of
  Var i -> singleton i
  App e1 e2 -> union (freeVars e1) (freeVars e2)
  Lam i e -> difference (freeVars e) (singleton i)
\end{verbatim}

We assume that we have some implementation of substitutions as maps of
variables to terms, although we don't require any particular implementation.

\begin{verbatim}
data Subst t -- opaque
\end{verbatim}

Substitutions have a function \tc{domain}, that we define solely within the logic
language.

\begin{verbatim}
{-@ measure domain :: Subst e -> Set Int @-}
\end{verbatim}

This is how purely logic functions are declared. The function \tc{domain} stands
for the set of variables in the domain of a substitution. However \tc{domain} is
an uninterpreted symbol, it doesn't have a definition beyond its type signature.
The meaning of \tc{domain} is given by the refinement type signatures in which
\tc{domain} appears:\unsure{Something we should be part of the discussion
  section at the end of the article, I think, is how do you actually instantiate
  these axioms with an concrete substitution type? Answer: Sounds good, you copy
  the assumptions to address whatever substitution representation is needed.}

\begin{verbatim}
assume lookupSubst
  :: k:Int
  -> xs:Subst e
  -> {m:Maybe e | isJust m == member k (domain xs) }

assume extendSubst
  :: s:Subst a
  -> i:Int
  -> a
  -> {v:_ | union (domain s) (singleton i) = domain v }
\end{verbatim}

With these signatures, whenever Liquid Haskell encounters an application of the
function \tc{lookupSubst}, it will assume that the key is in the domain of the
substitution if the lookup succeeds. Together \tc{domain}, \tc{lookupSubst}, and
\tc{extendSubst} axiomatizes our substitutions. We don't need to axiomatize
substitution, we could simply prove these lemmas, but using axioms makes sure
that our case studies don't depend on a particular choice of representation for
substitutions.

We can give now the following signature to \tc{substitute}
\begin{verbatim}
{-@
substitute
  :: scope:Set Int
  -> s:Subst (ScopedExp scope)
  -> ScopedExp (domain s)
  -> ScopedExp scope
@-}
substitute :: Set Int -> Subst Exp -> Exp -> Exp
\end{verbatim}
Remarkably, the implementation for \tc{substitute} is unchanged from the
implementation, without static scope checking, of
Figure~\ref{rapier-style-substitution}. This won't always be the case, but this
exemplifies how using Liquid Haskell to enforce invariants tends to great less
boilerplate than a type-based approach.

The type of lambda terms is also unchanged, as the well-scoping invariant is
applied to a whole term at once. A nice consequence of that is that functions
that don't benefit from all the scope checking business can simply take a naked
term and ignore it. The \tc{freeVars} function, for example, is implemented on
naked terms.\unsure{I'm considering adding a comment on the fact that we can use
  freeVars to provide an initial scope for the substitute function. Note:
  the foil starts with an identity substitution, that is, one that maps every
  variable to itself. And we do the same in our unification code. The substitution
  domain can be narrowed if desired, but starting with the identity doesn't affect
  the static checks.}

Our refinement type signature of \tc{substitute} follows the type signature of
\citeauthor{maclaurin23} to the letter. Though it addresses almost all of the
properties from Section~\ref{the-rapier-with-stronger-types}, it still misses
Property~(\ref{req:always-rename}), which we discuss next.

\subsection{A hybrid approach}
\label{ensuring-the-scope-set-is-checked}

We can introduce the following bug in \tc{substitute} from
Figure~\ref{rapier-style-substitution}, and Liquid Haskell, will
be blind to it with the refinement type signature that we provided.
\begin{verbatim}
  ...
  | member i scope ->
      Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e
\end{verbatim}
Liquid Haskell flags no errors but the program will still misbehave as
follows (in pseudo-Haskell).

$$\codeblocksize{\tc{substitute}~\{\tc{x}\}~(\lambda{}\tc{x}. \tc{y}) [\tc{y}:=\tc{x}] = (\lambda{}\tc{x}. \tc{x})}$$

So what gives? The binder \tc{i} is now capturing free variables in the
range of the substitution. The signature is, in fact, indifferent to whether
the binder \tc{i} is already present or not in the scope set. There's not
mechanism to prevent adding a binder that is already present in the scope set.
And, more to the point, how could there be? “Never add a binder to the scope set that is already
present” isn't a set theoretical property. It's not even a functional property.
It is a kind of temporal invariant.

Such temporal invariants aren't naturally expressed in the logic of Liquid Haskell.
But they're quite easy to implement with abstract types. So let's use an abstract
type. What we need to do is to ensure that whenever we see a new binder it must
be tested against the scope, and that this test is packaged together with fresh
name generation.

We follow the foil (see Section~\ref{the-rapier-with-stronger-types}) and
introduce an abstract type \tc{Scope} and a function \tc{withRefreshed}. \improvement{Add member in the code snippet} The types are a little
simpler because we don't need existential quantification to reflect value-level
objects at the type level, but otherwise these are the same functions and types
as in Section~\ref{the-rapier-with-stronger-types}.
\begin{verbatim}
newtype Scope = UnsafeScope { unsafeUnScope :: (Set Int) }
{-@
predicate Member E S = Set.member E (unsafeUnScope S)

withRefreshed :: s:Scope -> i:Int
  -> {p:(Scope, Int) |
       not (Member (snd p) s) && fst p == union s (singleton (snd p))}
@-}
withRefreshed :: Scope -> Int -> (Scope, Int)
withRefreshed (UnsafeScope s) i
  | Set.member i s = let j = freshVar s in (UnsafeScope (insert j s), j)
  | otherwise = (UnsafeScope (insert i s), i)
\end{verbatim}

We needed to add a refinement type signature to \tc{withRefreshed} to serve as
glue with the Liquid Haskell world. This refinement type signature tells Liquid
Haskell precisely that \tc{withRefreshed} does both membership checking and
fresh variable call: the variable returned by \tc{withRefreshed} isn't in the
old scope but is in the new scope.

It then suffices to seal the type \tc{Scope} to enforce that binders are always
refreshed when traversed.\change{Here we need a discussion of what sealing means,
which could be the place to discuss the need for the Member predicate alias as well.}
The full code for this example can be found in the
file \tc{Subst2.hs}.\footnote{A solution with a sealed scope type: \sourcefile{Subst2.hs}}

% The second approach, avoid introducing \tc{withRefreshed} and modifying the
% types in the program by providing a more stringent refinement type for
% \tc{substitute}.

% \begin{verbatim}
% substitute
%   :: scope:Set Int
%   -> s:Subst (ScopedExp scope)
%   -> ei:ScopedExp (domain s)
%   -> {v:Exp | freeVars v == freeVarsSubst (freeVars ei) s}
% \end{verbatim}

% In this signature we are spelling exactly what the expected free variables in the result are.
% We use a function \tc{freeVarsSubst} such that
% \tc{freeVarsSubst (freeVars e) s} computes the free variables in the range of the
% substitution \tc{s} that is actually used when applying it
% to the expression \tc{e}. We provide an example representation for substitutions and
% a schematic presentation of \tc{freeVarsSubst}, but in our implementation we
% are careful to keep the checks agnostic on the actual representation of
% substitutions.

% \begin{verbatim}
% type Subst e = [(Int, e)]
% freeVarsSubst :: Set Int -> Subst Exp -> Set Int
% freeVarsSubst used [] = empty
% freeVarsSubst used ((i, e) : xs) =
%   | member i used = -- only take the first occurrence of i
%       union (freeVars e) (freeVarsSubst (difference used (singleton i)) xs)
%   | otherwise = freeVarsSubst used xs
% \end{verbatim}

% Unless we rename all the binders unconditionally, it is no longer
% possible to ignore the scope set when going under binders since the calculation
% of free variables doesn't add up:
% If the name of the binder is in the free variables of the range of the substitution,
% it may show up in the free variables of the result, but leaving it unrenamed would
% cause the call to the function \tc{freeVars} in the expected return refinement type
% to disagree.

% Unfortunately, this refinement type signature is more laborious to check, as
% \tc{free\-Vars\-Subst} requires roughly one lemma per case of the \tc{subs\-ti\-tute}
% function.

% \begin{verbatim}
% lemmaFreeVarsSubstSing :: i:_ -> s:_
%   -> { freeVarsSubst (singleton i) s == fromMaybe empty (lookupSubst i s) }

% lemmaFreeVarsSubstUnion :: s1:_ -> s2:_ -> s:_
%   -> { freeVarsSubst (union s1 s2) s
%          == union (freeVarsSubst s1 s) (freeVarsSubst s2 s) }

% lemmaFreeVarsSubstExtend
%   :: scope:_ -> used:_
%   -> i:_ -> {e:_ | Data.Set.null (intersection (freeVars e) scope)}
%   -> s:Subst (ScopedExp scope)
%   -> { freeVarsSubst (difference used (singleton i)) s ==
%        difference (freeVarsSubst used (extendSubst s i e)) (freeVars e)
%      }
% \end{verbatim}

% Each lemma requires writing a recursive function for Liquid Haskell to
% check it, which is additional effort. Here's the proof for
% \tc{lemma\_free\-Vars\-Subst\_union}.

% \begin{verbatim}
% lemmaFreeVarsSubstUnion :: Set Int -> Set Int -> Subst Exp -> ()
% lemmaFreeVarsSubstUnion _ _ [] = ()
% lemmaFreeVarsSubstUnion s1 s2 ((i, _) : xs) =
%   lemmaFreeVarsSubstUnion
%     (difference s1 (singleton i)) (difference s2 (singleton i)) xs
% \end{verbatim}

% The recursive function follows the structure of an inductive proof,
% with much of the folding, unfolding, and set properties applied
% automatically. And this is similar for the proofs of the other lemmas.
% Then the lemmas need to be applied in the cases of \tc{substitute}.

% \begin{verbatim}
% substitute scope s e0 = case e0 of
%   Var i -> case lookupSubst i s of
%     Nothing -> e0
%     Just e -> e ? lemmaFreeVarsSubstSing i s
%   App e0 e1 ->
%     App (substitute scope s e0) (substitute scope s e1)
%       ? lemmaFreeVarsSubstUnion (freeVars e0) (freeVars e1) s
%   Lam i e
%     | member i scope,
%       let j = freshVar scope ->
%         Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
%           ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var j) s
%     | otherwise ->
%         Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e
%           ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var i) s
% \end{verbatim}

% The operator \tc{?} is an alias for function \tc{const = \textbackslash x \_ -> x} and
% brings the lemma into consideration of Liquid Haskell when checking the
% first argument without evaluating the recursive function that stands for
% the lemma proof. This solution is available in the file
% \tc{Subst3.hs}\footnote{A solution that addresses all requirements without
%   changing types in the program: \sourcefile{Subst3.hs}}\change{A single Subst
%   file please}
% in our repository.


\subsection{Comparison}

When using Liquid Haskell we needed to implement the
\tc{freeVars} function, provide the \tc{ScopedExp} refined type, and the refinement
type signatures of the substitution primitives. Contrast with an abstract-type based
approach where a lot primitives must be provided by the abstract interface. The foil,
in particular, needs several types, type classes, and primitive functions.
\unsureF{Shall we discuss here that LH is checking a slightly different set of properties?
We don't check property (2), but we do check that non-renamed binders are removed from
the domain of the substitution, which the foil leaves to the trusted code.}

\unsure{[Arnaud] I'm not sure yet whether I prefer this subsection to be here,
  or together with the evaluation section.}
Liquid Haskell ensures most requirements with little assistance
because it is delegating much of the work to an underlying SMT solver.
SMT solvers are tools that decide whether (usually first order) logic formulas are
satisfiable and provide dedicated mechanisms to reason about various theories
(sets, strings, arrays, integers, reals, etc).

In the case of capture-avoiding substitution, multiple queries that
Liquid Haskell gives to the SMT solver involve reasoning on sets, thus
making effective use of its capabilities. Moreover, the expression of
relationships between arguments and result is fairly natural with
refinement types. When there are lemmas to prove, despite of being
additional effort to write, they still have proofs that don't require
a lot of creativity.

On the other hand, an approach like the foil does need the author to
think carefully about how to encode the various static checks with the
type checker, a non trivial supporting library needs to be written,
and the effort might need further iterations when accounting for
additional properties.
We will return to this latter aspect in Section~\ref{SMT-solvers-for-interface-checks}.


\section{Unification}
\label{unification}

Now that we have established the refined rapier interface, let us now show how it
can be applied to a more realistic example: solving first-order equational
formulas. Specifically, we'll be solving a form of hereditary Harrop formulas in
the Herbrand domain. This is the sort of unification problem which can show up
when typechecking programs with GADTs~\cite{schrijvers09}. Scope management in
such a solver is a much trickier business than in the case of mere substitutions
and, in the authors' experience, something where any help from the compiler is welcome.
The source code of this section can be found in the file
\tc{Unif.hs}.\footnote{Source code of unification: \sourcefile{Unif.hs}}

In addition to variables, still represented as integers, we have unification
variables. Unification variables have their own scope: the formula
$\exists x. \forall y. x=y$ doesn't have a solution. It will be reduced to a
formula of the form $f_{x} = y$ where $f_{x}$ is a unification variable; we very much
don't want this unification problem to succeed\improvement{I think we should
  use a better notation to distinguish unification variables from rigid
  variables.}: we shall make it so that $y$ isn't in the permissible scope for $f_{x}$.

Furthermore, we will perform substitutions, substitutions are blocked by
unification variables as we don't know what they stand for yet. So a unification
variable, in our syntax, is a pair $(f, [x_0:=t_0,\ldots,x_n:=t_n])$ of a
unification variable proper and a suspended substitution. Where
$\{x_0,\ldots,x_{n}\}$ is the scope of $f$. Such a pair is akin to a skolem
function application $f(t_0,\ldots,t_n)$. Notice in particular, how the solution
of $f$ can only have free variables in $\{x_0,\ldots,x_{n}\}$, but
$(f, [x_0:=t_0,\ldots,x_n:=t_n])$ may live in a different scope altogether. This
is what makes this type of unification problem tricky.

\begin{verbatim}
type Var = Int
type SkolemApp = (Var, Subst Term)
\end{verbatim}

This way, our formula $\exists x. \forall y. x=y$ will be reduced to
$(f_{x},[]) = y$ which doesn't have a solution. On the other hand
$\forall x. \exists y. x = y$ becomes $x = (f_{y}, [x:=x])$ so $x$ is a solution
for $f_{y}$ and the formula is solvable.

\begin{verbatim}
data Term
  = V Var | SA SkolemApp | U | L Term | P Term Term deriving

data Formula
  = Eq Term Term               -- equality
  | Conj Formula Formula       -- conjunctions
  | Then (Term, Term) Formula  -- a = b => f
  | Exists Var Formula         -- existential quantification
  | Forall Var Formula         -- universal quantification
\end{verbatim}

Our term language allows for variables, skolem applications, and some artificial
data constructors (i.e. injective functions). The language of formulas has
equality, conjunction, existential and universal quantification, and it also
has a form of implication that only allows for equalities in the antecedent.
The conception is driven by the simplest language that still would allow to
express something of practical interest like constraints of generalized
algebraic data types (GADTs)~\cite{schrijvers09}.

Our unification algorithm is then expressed in Figure~\ref{conditional-unification}.
When unification fails, we return an incomplete list of solutions, that is one that
doesn't provide solutions for all the skolems in a formula.
There are a few preparation passes on unification formulas that we have elided since
they aren't essential to the discussion in this section.
Existential variables would be replaced with skolem applications, equalities of
data constructors like $P a b = P c d \Rightarrow f$ are split to
$a = c \land b = d \Rightarrow f$, formulas are normalized to prenex form, variables
are renamed to avoid name captures, etc. We have functions \tc{substitute} and
\tc{substituteSkolems} to apply substitutions in terms and substitutions of skolems
in formulas. We have a function \tc{skolemSet} to collect the skolems of a
term. And we have a function \tc{fromListSubst} to construct a substitution from
a list of pairs \tc{[(Var, Term)]}.

\begin{figure}
\begin{verbatim}
unify :: Formula -> [(Var, Term)]
unify (Forall v f) = unify f
unify (Exists v f) = unify f
unify (Conj f1 f2) = unify f1 ++ unify f2
unify (Then (t0, t1) f2) =
  let unifsT1 = unifyEq t0 t1
      unifsT1Subst = fromListSubst unifsT1
   in unifsT1 ++ unify (substituteSkolems unifsT1Subst f2)
unify (Eq t0 t1) = unifyEq t0 t1

unifyEq :: Term -> Term -> [(Var, Term)]
unifyEq t0 t1@(SA (i, s))
  | Just s' <- inverseSubst $ narrowForInvertibility (freeVars t0) s
  , let t' = substitute s' t0
  , not (Set.member i (skolemSet t'))
  , Set.isSubsetOf (freeVars t') (domain s)
  = [(i, t')]
unifyEq t0@(SA _) t1 = unifyEq t1 t0
unifyEq _ _ = []

-- | @narrowForInvertibility vs s@ removes pairs from @s@ if the
-- range is not a variable, or if the range is not a member of @vs@.
narrowForInvertibility :: Set Var -> Subst Term -> Subst Term
narrowForInvertibility vs (Subst xs) =
  Subst [(i, V j) | (i, V j) <- xs, Set.member j vs]

inverseSubst :: Subst Term -> Maybe (Subst Term)
inverseSubst (Subst xs) = fmap Subst (go xs)
  where
    go [] = Just []
    go ((i, V j) : xs) = fmap ((j, V i) :) (go xs)
    go _ = Nothing
\end{verbatim}
\caption{Conditional unification}
\Description{Haskell implementation of condition unification}
\label{conditional-unification}
\end{figure}

The function \tc{unifyEq} defines what a good solution should be.
One of the conditions is that whatever term \tc{t'} is proposed
as solution for a skolem \tc{i}, it needs to have as free variables only those in the
domain of the substitution defining the skolem application
(\textit{scope check}). Another
condition is that the skolem \tc{i} should not occur in the solution
\tc{t'} (\textit{occurs check}). And since we are inverting a substitution to find
\tc{t'}, we might not find solutions if we cannot invert the
substitution. This implementation only inverts substitutions where
variables are mapped to variables. That is, we solve $(f, [z:=x]) = L(L(x))$
to get the solution $(f, L(L(z)))$ but we do not try solving $(f, [z:=L(x)]) = L(L(x)))$.

\subsection{Checking \tc{unifyEq}}

We start introducing static checks by providing a refinement type signature to
the function \tc{unifyEq}, which encodes the scope check, the occurs check,
and the relationship of skolems present in the result and in the arguments.

\begin{verbatim}
unifyEq
  :: t0:Term
  -> {t1:Term | unionCommutes (scopesTerm t0) (scopesTerm t1)}
  -> [(v :: Var
      , { t:Term |
            isSubsetOfJust (freeVars t)
              (IntMap.lookup v
                (IntMap.union (scopesTerm t0) (scopesTerm t1)))
          && not (Set.member v (skolemSet t))
          && intMapIsSubsetOf (scopesTerm t)
               (IntMap.union (scopesTerm t0) (scopesTerm t1))
        }
      )] / [terminationUnifyEq t0 t1]
\end{verbatim}

The function \tc{scopesTerm} is only used in refinement types and it produces
a projection of the skolem applications in a given term. Instead of returning
full skolem applications, it only provides the skolem name and the domain of
the substitution.

\begin{verbatim}
scopesTerm :: Term -> IntMap (Set Int)
scopesTerm (V i) = IntMap.empty
scopesTerm (SA (i, s)) = IntMap.insert i (domain s) (scopesSubst s)
scopesTerm U = IntMap.empty
scopesTerm (L t) = scopesTerm t
scopesTerm (P t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

In this function we are using the data type \tc{IntMap}, also coming from the
package \tc{containers}. Liquid Haskell can link the calls in this function
with the array theory that is used to represent maps in the SMT solver.
The function \tc{scopesSubst} provides the skolems present in the range of
the substitution.

We define the predicate \tc{isSubsetOfJust} to say that the lookup succeeds
and that it yields a superset of the first argument.

\begin{verbatim}
isSubsetOfJust :: Ord a => Set a -> Maybe (Set a) -> Bool
isSubsetOfJust xs (Just ys) = Set.isSubsetOf xs ys
isSubsetOfJust xs Nothing = False
\end{verbatim}

We assume the function \tc{IntMap.union} to be commutative despite of it being
defined as left-biased in the \tc{containers} package. This is because we
rely on the preceding passes of unification to ensure that everywhere a
skolem occurs, the domain of the substitution is always the same.

\begin{verbatim}
unionCommutes :: Set a -> Set a -> Bool
unionCommutes s0 s1 = IntMap.union s0 s1 == IntMap.union s1 s0
\end{verbatim}

The function \tc{intMapIsSubsetOf} is implemented by the authors in Liquid
Haskell, since it doesn't come from the package \tc{containers}. It returns
true if and only if all the key-value pairs of the first argument are contained
in the second.

The function \tc{terminationUnifyEq} is a metric that we provide so Liquid
Haskell can check that \tc{unifyEq} terminates. When the recursion is
structural, termination can be proved without extra considerations, but in
this case we are doing a recursive call that swaps the order of the arguments.
The metric that we provide must be greater or equal to 0 and must decrease on
each recursive call.

\begin{verbatim}
{-@ terminationUnifyEq :: Term -> Term -> {v:Int | v >= 0} @-}
terminationUnifyEq :: Term -> Term -> Int
terminationUnifyEq (SA _) _ = 1
terminationUnifyEq _ (SA _) = 0
terminationUnifyEq _ _ = 0
\end{verbatim}

When checking \tc{unifyEq}, the two first conjuncts of the return type can
be easily established since they match exactly the guards in the first equation.
The last conjunct demands more calculation.

If we substitute \tc{t} by \tc{substitute s'} in the last conjunct, we get that we
need to prove

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm (substitute s' t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

Liquid Haskell does compute this on its own. Then we can use the fact that substitution
preserves the skolems returned by \tc{scopesTerm} to arrive at

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

And this statement the SMT solver can prove on its own using the theory of arrays,
which can be used to implement maps. The only step that the user needs to spell out
is the property relating \tc{substitute} and \tc{scopesTerm}.

\begin{verbatim}
lemmaSubstituteScopesTerm
  :: s:Subst {ti:Term | isVar ti}
  -> t:Term
  -> { scopesTerm t = scopesTerm (substitute s t) }
\end{verbatim}

The range of the substitution \tc{s} is required to only contain variables, but
this is exactly what \tc{inverseSubst} produces!

\begin{verbatim}
isVar :: Term -> Bool
isVar (V _) = True
isVar _ = False

{-@ inverseSubst :: Subst Term -> {v:Subst {t:Term | isVar t} @-}
\end{verbatim}

Here is the proof of the lemma, which follows the recursive structure
of function \tc{substitute}.

\begin{verbatim}
lemmaSubstituteScopesTerm :: Subst Term -> Term -> ()
lemmaSubstituteScopesTerm s (SA (_, s1)) = lemmaComposeSubstDomain s1 s
lemmaSubstituteScopesTerm s U = ()
lemmaSubstituteScopesTerm s (L t) = lemmaSubstituteScopesTerm s t
lemmaSubstituteScopesTerm s (P t0 t1) =
    lemmaSubstituteScopesTerm s t0 `seq` lemmaSubstituteScopesTerm s t1
lemmaSubstituteScopesTerm s (V v) = case lookupSubst v s of
    { Nothing -> (); Just (V _) -> (); Just _ -> () }
\end{verbatim}

We cut the proof in the case of skolems with an assumption about the
skolems and domains of compositions of substitutions.

\begin{verbatim}
assume lemmaComposeSubstDomain
  :: s0:Subst Term -> s1:Subst {t:_ | isVar t}
  -> {   domain s0 == domain (composeSubst s0 s1)
      && scopesSubst s0 == scopesSubst (composeSubst s0 s1) }
\end{verbatim}


\subsection{Checking \tc{unify}}

In the same way as in the previous section, we start checking the function \tc{unify}
by providing a refinement type signature. This is a rephrasing of the refinement
types of \tc{unifyEq} when the input is a formula instead of a pair of terms. We
drop the third conjunct of \tc{unifyEq} as it is needed only to check \tc{unify} and
it doesn't need to be propagated further.

\begin{verbatim}
unify
  :: {f:Formula | consistentSkolemScopes f}
  -> [(v :: Var
      , { t:Term |
             isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f))
          && not (Set.member v (skolemSet t))
          && IntMap.isSubsetOf (scopesTerm t) (scopes f)
        }
      )] / [formulaSize f]
\end{verbatim}

The recursion of unify is not structural since in the implication case we
are chaining the recursive calls. Therefore we provide a termination
metric \tc{formulaSize} that counts the amount of connectives in a formula.
We also define a function \tc{scopes} analogous to \tc{scopesTerm} to obtain the skolems
of a formula.

\begin{verbatim}
scopes :: Formula -> IntMap Var (Set Int)
scopes (Forall _ f) = scopes f
scopes (Exists _ f) = scopes f
scopes (Conj f1 f2) = IntMap.union (scopes f1) (scopes f2)
scopes (Then (t0, t1) f2) =
  IntMap.union (scopesTerm t0) (IntMap.union (scopesTerm t1) (scopes f2))
scopes (Eq t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

We also define the predicate \tc{consistentSkolemScopes}, which ensures that
all occurrences of a skolem have the same domain in their substitutions.

\begin{verbatim}
consistentSkolemScopes :: Formula -> Bool
consistentSkolemScopes (Forall _ f) = consistentSkolemScopes f
consistentSkolemScopes (Exists _ f) = consistentSkolemScopes f
consistentSkolemScopes (Conj f1 f2) =
      consistentSkolemScopes f1
  && consistentSkolemScopes f2
  &&  unionCommutes (scopes f1) (scopes f2)
consistentSkolemScopes (Then (t0, t1) f2) =
     consistentSkolemScopes f2
  && unionCommutes (scopesTerm t0) (scopesTerm t1)
  && unionCommutes (IntMap.union (scopesTerm t0) (scopesTerm t1)) (scopes f2)
consistentSkolemScopes (Eq t0 t1) =
  unionCommutes (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

Liquid Haskell can check mostly automatically the refinement type signature of
\tc{unify}. In the equations for quantifiers, unfolding definitions of
\tc{scopes} plus the refinement type of the recursive calls suffices.
In the equation of conjunction, the theory of arrays of the SMT solver
kicks in to establish the first conjunct of the refinement type:

\begin{verbatim}
unionCommutes (scopes f1) (scopes f2)
=>
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f1)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
&&
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f2)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
\end{verbatim}

The antecedent of the above goal is established by \tc{consistent\-Skolem\-Scopes}
in the refinement type of the input. The consequent relates the refinement types
of the recursive calls to the expected refinement type of the result, as Liquid
Haskell knows that \tc{IntMap.\allowbreak union (scopes f1) (scopes f2)} stands for
\tc{scopes (Conj f1 f2)}. The second conjunct of the refinement type
is accepted as it is established by the recursive calls and \tc{unifyEq}
as is.

The other equations in \tc{unify} are checked using similar reasoning, all of it
automatic except for a lemma in the implication equation.

\begin{verbatim}
unify f@(Then (t0, t1) f2) =
    let unifsT1 = unifyEq t0 t1
        unifsT1Subst = fromListSubst unifsT1
     in unifsT1 ++ unify (substituteSkolems unifsT1Subst f2)
          ? lemmaScopeSubstSubset (scopes f) unifsT1Subst
\end{verbatim}

The lemma relates the skolems in the substitution \tc{unifsT1Subst}
with the skolems of the input formula.

\begin{verbatim}
assume lemmaScopeSubstSubset
  :: m0:IntMap (Set Int)
  -> s:Subst {t:Term | intMapIsSubsetOf (scopesTerm t) m0}
  -> { intMapIsSubsetOf (scopesSubst s) m0 }
\end{verbatim}

This lemma depends on the representation of substitutions and therefore is
assumed to work as the refinement type signature describes for the sake of
this study.


\subsection{Extending Liquid Haskell to support \tc{IntMap}}
\label{extending-liquid-haskell}

When we started our study, Liquid Haskell didn't support using the SMT solver
to reason with \tc{Map}s or \tc{IntMap}s.\footnote{Issue to support maps in the Liquid Haskell repository: \url{https://github.com/ucsd-progsys/liquidhaskell/issues/2534}}
In this section, we describe our modification to Liquid Haskell in order to address
this problem. While we can still use Liquid Haskell without these
changes, we would lose in automation. The tooling would require a lot more
lemmas from the user to check that the code handles the maps as expected.
All our modifications can be found in the files \tc{ifl25-\allowbreak liquidhaskell.patch}
and \tc{ifl25-\allowbreak liquid-\allowbreak fix\-point.patch}.\footnote{Patches for
liquidhaskell and liquid-fixpoint: \sourcefile{ifl25-liquidhaskell.patch} and
\sourcefile{ifl25-liquid-fixpoint.patch}}

We modified Liquid Haskell to leverage the SMT solver to reason with the type
\tc{IntMap (Set Int)}. These modifications can be easily adapted to
support other instantiations of \tc{Map a b} or \tc{IntMap b}, but a general
solution that can be reused for any instantiation of the type parameters still
needs to be implemented.

On the syntax front, Liquid Haskell allows to link a Haskell type with a particular
representation in the SMT solver.

\begin{verbatim}
{-@ embed IntMap * as IntMapSetInt_t @-}
\end{verbatim}

Here we are indicating that \tc{IntMap b} must be represented as \tc{IntMapSetInt\_t}
in the logic. \tc{IntMapSetInt\_t} is an alias for \tc{Array Int (Option (Set Int))}.
An array is an entity that associates keys with values, and which has an equality predicate,
and it is defined as one of the theories in SMT-LIB, the standard interface
to SMT solvers~\cite{BarFT-RR-25}.
The keys in this case are integers, and the values are either \tc{None} if the key
is not in the map, or \tc{Some s} if the key maps to a set \tc{s}. We name the data type
\tc{Option} to differentiated from Haskell's \tc{Maybe}, although both types are isomorphic.
We do not name it the same because the framework to connect to the SMT solver is
reused for other languages (e.g. \improvement{lehmann23}), and we prefer to keep
the implementation free of language specific details.
Here is the declaration of the \tc{Option} data type in SMT-LIB.

\begin{verbatim}
(declare-datatype Option (par (a) (None (Some (someVal a)))))
\end{verbatim}

We arranged for Liquid Haskell to include this declaration in the preamble of any
queries to the SMT solver. The types \tc{Array}, \tc{Int}, and \tc{Set} are already
known to the tooling.
It doesn't matter what type \tc{b} is instantiated to, the \tc{embed} annotation will
always set the same representation for \tc{IntMap b}, and this is a limitation that
would need to be addressed to support maps properly.

The array theory allows to describe how to retrieve the value associated with
a key, and how to update the value. On the Haskell front, we link these operations
to those of the \tc{IntMap b} type.

\begin{verbatim}
define IntMap.empty = (IntMapSetInt_default None)
define IntMap.insert x y m = IntMapSetInt_store m x (Some y)
define IntMap.lookup x m =
  if (isSome (IntMapSetInt_select m x)) then
    (GHC.Internal.Maybe.Just (someVal (IntMapSetInt_select m x)))
  else
    GHC.Internal.Maybe.Nothing
\end{verbatim}

The operations \tc{IntMapSetInt\_default}, \tc{IntMapSetInt\_store}, and \tc{IntMapSetInt\_select}
are aliases that we implemented in Liquid Haskell to call to the array operations.
In the case of \tc{lookup}, we translate the \tc{Option} type to Haskell's \tc{Maybe}.

The implementation of union, intersection,
difference, and subset checks for maps, however,
need operations beyond the standard interface, and not all SMT solvers can support
them. In our implementation we used the \tc{map} operation of the
Z3 SMT solver. The following snippet contains the implementation of
\tc{intMapIsSubsetOf} in SMT-LIB, and we also feed these declarations to the
SMT solver in a preamble to the queries.

\begin{verbatim}
; Similar to do {a0 <- oa0; a1 <- oa1; guard (a0 /= a1); pure a0}
(define-fun difference_strict_p2p
  ((oa0 (Option (Set Int)))
   (oa1 (Option (Set Int))))
  (Option (Set Int))
  (match oa0
    ((None None)
     ((Some a0) (match oa1
                  ((None oa0)
                   ((Some a1) (ite (= a0 a1) None oa0))))))))

; Similar to: empty == zipWith difference_strict_p2p xs ys
; where zipWith applies the function pointwise to the values in the
; arrays
(define-fun IntMapSetInt_isSubsetOf
  ((xs (Array Int (Option (Set Int))))
   (ys (Array Int (Option (Set Int)))))
  Bool
  (= ((as const (Array Int (Option (Set Int)))) None)
     ((_ map IntMapSetInt_difference_strict_p2p) xs ys)))
\end{verbatim}

Besides the limitation of the \tc{embed} annotation, another barrier for
proper support is that old versions of SMT-LIB require user defined
functions to have monomorphic types. This means, for instance, that
the type of \tc{IntMapSetInt\_isSubsetOf} cannot be generalized to work
on any \tc{IntMap}.

While newer versions of the standard allow
for polymorphic types, these still need to be implemented by SMT solvers.
Until the implementations catch up with the standard, feeding operations with
monomorphic types will require Liquid Haskell to be smart about generating
these operations with the appropriate types, instead of putting them in a
preamble once and for all queries.


\subsection{Other limitations of Liquid Haskell}
\label{limitations-of-liquid-haskell}

The source code of our unification example lists various defects to fix
in the user experience that required workarounds. A few of them seem to
be about ill-resolved names when translating Haskell identifiers to the
logic language, and there is one example of a function rejected by the
termination checker that should arguably be accepted.

In our code we have been using the simplest possible style of programming.
There are no GADTs, no type families, not even type classes, though
Liquid Haskell has some support for type classes~\cite{liu20}. At the moment,
pushing for more demanding programming patterns is likely to surface more
inconveniences. Aiming for the simplest style is, therefore, a constraint of
the current implementation, unless one is willing to contribute fixes or
look for the workarounds.

On the bright
side, none of the implementation issues that we have encountered in these
examples will require answering open research questions.
But for further insight on the challenges of using Liquid Haskell,
Gamboa et al.~\cite{gamboa25} report on a study that collects the voices
of its users.

\section{Evaluation of SMT solvers for interface checks}
\label{SMT-solvers-for-interface-checks}

As the case studies in this paper reinforce, SMT solvers can go a long way in
automating static checks. Insight from the user is necessary, however,
when the properties to check are not handled by any of the theories in the
solver.

When the property involves user defined recursive functions,
sometimes it still can be proved automatically if it is attached to the
refinement type signature of the function. This is the case of the refinement
types of functions \tc{substitute} and \tc{unification}, where the recursion
of the proof supports the inductive reasoning required to established the
property.

When the property cannot be expressed in the signature of a recursive function,
like the lemmas that have been presented, writing lemmas becomes necessary. The
inconvenience is two-fold. In the one hand, the lemma needs to be precisely
written and then demonstrated. And in the other hand, the user needs to figure
out the right set of parameters to apply it to at the sites where it is needed.

These inconveniences are alleviated by the fact that one can still use the
SMT solvers to write abbreviated demonstrations of the lemmas. Additionally,
it would be plausible that one can rely on additional mechanisms to help
discover the parameters to which they are applied. In the case of Liquid
Haskell, there is an implementation of automatic rewrite rules~\cite{grannan22}
that is meant to address the problem for lemmas about equalities.

It would be possible to ask the SMT solver to instantiate the lemma parameters
as needed by introducing assertions with universal quantification. For instance,
the universally quantified lemma \tc{lemma\-FreeVars\-Subst\-Union} follows.

\begin{verbatim}
(assert
  (forall
    ((s (Subst Term))
     (s1 (Set Int))
     (s2 (Set Int)))
    (freeVarsSubst (union s1 s2) s
       == union (freeVarsSubst s1 s) (freeVarsSubst s2 s))))
\end{verbatim}

When checking satisfiability of other assertions, the SMT solver
will try to use the universally quantified assertion. Unfortunately, the
behavior of the procedures to find instantiations for quantified variables are
not easy to predict. This is why Liquid Haskell refrains from doing it~\cite{vazou13}.

On the performance front, all of the SMT-LIB queries in the unification example run
in 6 seconds, 0.04 seconds for \tc{Subst2.hs}, and 0.03 seconds in \tc{Subst1.hs}.
That is sometimes faster than it takes to compile the modules with the GHC compiler.
Where things get slower is when measuring Liquid
Haskell, which spends several seconds checking the examples and interacting with the
SMT solver (37 seconds checking unification, 4 seconds checking \tc{Subst2.hs},
1.5 seconds checking \tc{Subst1.hs}). The authors deem that performance of Liquid Haskell
can be improved to approach that of the SMT solver queries, and probably further by
reducing the amount of queries.

Other than using an SMT solver in the fashion of Liquid Haskell, F*~\cite{swamy16},
Why3~\cite{filli13}, or Dafny~\cite{leino17},
the alternatives to implementing interface checks are either to encode the checks in
the type-checker, or to migrate to a dependently typed language for the sake of
static checking~\cite{haftmann10, breitner18, carr22}. Of these alternatives,
we feel like using the type-checker is among the most pragmatic. Maclaurin et al. make
a fine demonstration about the foil.

Perhaps one of the biggest compromises when encoding properties in the type-checker
is that one needs to narrow the expressible properties to a feasible set that allows
to write a supporting library. If we wanted to have static checks like those of the
unification example, ensuring that the return terms satisfy the scope check and the
occurs check would require new type encodings. Or in other words, new type indices
need to be conceived to relate the parameters of the function \tc{unify}.
$$\mathit{unify} :: \mathit{Formula}\ f_1 \ldots f_n -> [(\mathit{Var}\ v_1 \ldots v_m, \mathit{Term}\ t_1 \ldots t_r)]$$

Then there would be the effort of writing a library, and later on there would be the
effort of composing the encodings of different libraries when more than one such
is needed. Suppose we wanted to check in the unification example that the
function to apply substitutions passes the static checks of
Section~\ref{capture-avoiding-substitution}. With
refinement types we need to add the corresponding conjuncts to the predicates.

\begin{verbatim}
- substituteFormula
-   :: Set Int
-   -> Subst Term
-   -> f:Formula
-   -> {v:Formula | formulaSize f == formulaSize v}
-
+ type ScopedFormula S = {f:Formula | isSubsetOf (freeVarsFormula f) S}
+ type ScopedTerm S = {t:Term | isSubsetOf (freeVars t) S}
+
+ substituteFormula
+   :: scope:Set Int
+   -> s:Subst (ScopedTerm scope)
+   -> f:ScopedFormula (domain s)
+   -> {v:ScopedFormula scope | formulaSize f == formulaSize v}
\end{verbatim}

Less planning and setup seems necessary when composing refinement types, and
then we can hope SMT solvers to continue to check the same constraints
they were fed when the properties where checked in isolation.

The type-checker approach, however, is likely to produce error messages that
are easier to fix, provided that the user goal is feasible.
The user is guided into correcting the errors
by the types and the operations of the supporting library. With SMT solvers,
there is always the question of whether a goal is provable or not in the
theories at hand. Is there some additional lemma that is necessary about the user defined
functions? The user has to figure it out on her own. How are the assumptions
insufficient to prove the goal? The user has to compute it on her own too,
although it is plausible that counterexamples or better location information~\cite{webbers24}
can be proposed by the tooling when the integration matures.

As an example, let us consider the lemma \tc{lemma\-FreeVars\-Subst\-Union} discussed in
Section~\ref{ensuring-the-scope-set-is-checked}.
If we drop this lemma from the definition of \tc{substitute}, we get the following
error message, heavily edited for presentation.

\begin{verbatim}
tests/rapier/Subst3.hs:141:7: error:
    Liquid Type Mismatch
    The inferred type
      VV : {v : Exp | v == App ?b ?c
                      && freeVars v == union (freeVars ?b) (freeVars ?c)}
    is not a subtype of the required type
      VV : {VV : Exp | freeVars VV == freeVarsSubst (freeVars ?a) s}
    in the context
      ?c : {?c : Exp | ?c == substitute scope s e1
                       && freeVars ?c == freeVarsSubst (freeVars e1) s}

      ?b : {?b : Exp | ?c == substitute scope s e0
                       && freeVars ?b == freeVarsSubst (freeVars e0) s}

      ?a : {?a : Exp | isSubset (freeVars ?a) (domain s)
                       && ?a == App e0 e1
                       && freeVars ?a == union (freeVars e0) (freeVars e1)}

      scope : Set Int
      s : Subst Exp
      e0 : Exp
      e1 : Exp
    Constraint id 33
    |
141 |       App (substitute scope s e0) (substitute scope s e1)
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
\end{verbatim}

We can get quickly that the goal is the returned refinement type of \tc{substitute}.
But to get at the missing lemma, we need to calculate with the assumptions that
Liquid Haskell has presented.
To start, we could substitute \tc{freeVars VV} in the goal with what the predicate
in the inferred refinement type defines it to be.

\begin{verbatim}
union (freeVars ?b) (freeVars ?c) == freeVarsSubst (freeVars ?a) s
\end{verbatim}

Then we could substitute the various calls to \tc{freeVars} with what
the refinement types of \tc{?a}, \tc{?b}, and \tc{?c} define them to be.

\begin{verbatim}
union (freeVarsSubst (freeVars e0) s) (freeVarsSubst (freeVars e1) s)
  == freeVarsSubst (union (freeVars e0) (freeVars e1)) s
\end{verbatim}

We have already a first sight of the missing assumption, but to get from
there to the statement of \tc{lemmaFreeVarsSubstUnion}, we still need
to generalize the calls to \tc{freeVars}.

\begin{verbatim}
freeVarsSubst (union s1 s2) s ==
  union (freeVarsSubst s1 s) (freeVarsSubst s2 s)
\end{verbatim}

It is an open question whether we can hope the tooling to effectively
assist these calculations one day.


\section{Conclusions}
\label{conclusions}

We have presented two case studies to contrast the use of SMT solvers
with more traditional approaches based on type checking with strong types. In
our analysis, we tested the ability of SMT solvers to effectively automatize
the static checks otherwise left to the type system.

We found that refinement types enable a direct expression of properties,
particularly when the SMT solver supports the relevant theories. Reasoning
mechanisms are reused from the existing tooling, instead of encoding them
in the type checker. This makes easier both implementing static checks and
composing the properties coming from different sources.

However, integrating SMT solvers for static checks still presents some
challenges. One of them is maturing the existing integrations until they are
feasible to use in industrial setting. Another one is deriving useful
corrective actions from the error messages. And a last challenge is lowering
the checking overhead until it is close to the time required for queries to
the SMT solver alone.

The generality of the approach, and the simplicity with which it enables
composition of different static checks, are unique features that make it a strong
candidate to impact programming practice in the future.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\end{document}

% LocalWords:  invariants axiomatizes axiomatize
